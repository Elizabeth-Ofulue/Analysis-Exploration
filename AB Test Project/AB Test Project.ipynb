{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze A/B Test Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "> - [Introduction](#intro)\n",
    "> - [Data Cleaning/Wrangling](#data_cleaning/wrangling)\n",
    "> - [Part I - Probability](#probability)\n",
    "> - [Part II - A/B Test](#ab_test)\n",
    "> - [Part III - Regression](#regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "### Introduction\n",
    "\n",
    "> A/B tests are very commonly performed by data analysts and data scientists. It is used to test changes on a web page by running an experiment where a control group sees the old version, while the experiment group sees the new version. A metric is then chosen to measure the level of engagement from users in each group. These results are then used to judge whether one version is more effective than the other. A/B testing like hypothesis testing comprises of a null and alternative hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "### Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This project involves working to understand the results of an A/B test run by an e-commerce website. The company has developed a new web page in order to try and increase the number of users who \"convert,\" meaning the number of users who decide to pay for the company's product. \n",
    "\n",
    "> The objective is to help the company understand if they should implement the new page, keep the old page, or perhaps run the experiment longer to make their decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='probability'></a>\n",
    "### Data Cleaning/Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing liraries to be used\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#We are setting the seed to assure you get the same answers on quizzes as we set up\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the dataset into a variable and observing the first few rows\n",
    "df = pd.read_csv('ab_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(294478, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the number of rows and columns using the shape function\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the number of unique users in the unique_id column\n",
    "\n",
    "df.user_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11965919355605512"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the proportion of users converted\n",
    "\n",
    "df['converted'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id         3893\n",
       "timestamp       3893\n",
       "group           3893\n",
       "landing_page    3893\n",
       "converted       3893\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing for the number of times the treatment group was mismatched with the old_page instead of the new_page,\n",
    "\n",
    "df[(df['group'] == \"treatment\") != (df['landing_page'] ==\"new_page\")].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id         0\n",
       "timestamp       0\n",
       "group           0\n",
       "landing_page    0\n",
       "converted       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing for the numer of rows with missing data\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For the rows where **treatment** does not match with **new_page** or **control** does not match with **old_page**, we cannot be sure if this row truly received the new or old page. Therefore inorder to improve the accuracy of the dataset to be tested, these rows are removed. \n",
    "\n",
    "> After the rows are removed, a new dataset is created and stored in a new dataframe in **df2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning the index of rows in which the new_page and treatment dont match to a variable\n",
    "\n",
    "d = df[(df['group'] == \"treatment\") != (df['landing_page'] ==\"new_page\")].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the index of rows assigned to variable d from the df dataframe and assigning the remaining rows to a new dataframe df2\n",
    "\n",
    "df2 = df.drop(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290585, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for the shape of the new dataset\n",
    "\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doublecheckong to see if all of the correct rows were removed \n",
    "\n",
    "df2[((df2['group'] == 'treatment') == (df2['landing_page'] == 'new_page')) == False].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. How many unique **user_id**s are in **df2**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for the number of unique user_ids in the new dataframe df2\n",
    "\n",
    "df2.user_id.nunique()\n",
    "\n",
    "# It is observed that there seems to be a duplicated user_id as the number of unique user_ids is less than the number of rows of the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "773192    2\n",
       "630732    1\n",
       "811737    1\n",
       "797392    1\n",
       "795345    1\n",
       "         ..\n",
       "650647    1\n",
       "648598    1\n",
       "654741    1\n",
       "652692    1\n",
       "630836    1\n",
       "Name: user_id, Length: 290584, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for the duplicate user_id by using the value_counts function\n",
    "\n",
    "df2.user_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-09 05:37:58.781806</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "1899   773192  2017-01-09 05:37:58.781806  treatment     new_page          0\n",
       "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the row information of the duplicate id\n",
    "\n",
    "df2.query('user_id == 773192')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing one of the rows with the duplicate user_id using the row index\n",
    "df2.drop(2893, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "### Part I - Proability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the probability of an individual converting regardless of the page received\n",
    "\n",
    "df2.converted.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1203863045004612"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the probability that an individual in the control group converted.\n",
    "\n",
    "df2.query('group == \"control\"')['converted'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11880806551510564"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the probability of an individual that was in the treatment group and converted.\n",
    "\n",
    "df2.query('group == \"treatment\"')['converted'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000619442226688"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the probability that an individual received the new page\n",
    "\n",
    "(df2.landing_page == \"new_page\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> It is observed that the probability an individual receiving the new page  is approximately equal regardless of the group. From the analysis carried out and probability obtained for both the control and experiment groups, there is no sufficient evidence to show that the new treatment page leads to more conversions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ab_test'></a>\n",
    "### Part II - A/B Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Considering the need to make a decision just based on all the data provided, it is assumed that the old page is better unless the new page proves to be definitely better at a Type I error rate of 5%.\n",
    "\n",
    "> At a type 1 error rate of 5%, the null and alternative hypothesis in terms of notations **$p_{old}$** and **$p_{new}$**, which are the converted rates for the old and new pag are given as:\n",
    "\n",
    "> * $H_0 : P_{new} - P_{old} =< 0$ \n",
    "> * $H_1 : P_{new} - P_{old} > 0$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If under the null hypothesis, it is assumed that $p_{new}$ and $p_{old}$ both have \"true\" success rates equal to the **converted** success rate regardless of page - then $p_{new}$ and $p_{old}$ are equal. Furthermore, it is also assumed they are equal to the **converted** rate in **ab_data.csv** regardless of the page. <br><br>\n",
    "\n",
    "> The null and alternative hypothesis will therefore be given as;\n",
    "\n",
    "> * $H_0 : P_{new} - P_{old} = 0$ \n",
    "> * $H_1 : P_{new} - P_{old} != 0$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing the conversion rate for p_new under the null\n",
    "\n",
    "p_new = df2['converted'].mean()\n",
    "p_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing the conversion rate for p_old under the null\n",
    "\n",
    "p_old = df2['converted'].mean()\n",
    "p_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145310"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the number of individuals in the treatment group\n",
    "\n",
    "n_new = df2.query('group == \"treatment\"').shape[0]\n",
    "n_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145274"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the number of individuals in the control group\n",
    "\n",
    "n_old = df2.query('group == \"control\"').shape[0]\n",
    "n_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the difference between the conversion rates for p_new and p_old under the null.\n",
    "\n",
    "p_new - p_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using a sample size for each page equal to the ones in **ab_data.csv**, the sampling distribution is computed for the difference in **converted** between the two pages over 10,000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulating n_new transactions with a conversion rate of p_new under the null\n",
    "\n",
    "new_page_converted = np.random.choice([0,1], size=n_new, p = [1-p_new, p_new])\n",
    "new_page_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulating n_old transactions with a conversion rate of p_old under the null \n",
    "\n",
    "old_page_converted = np.random.choice([0,1], size=n_old, p = [1-p_old, p_old])\n",
    "old_page_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0008346354424162566"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the differences between the mean simulated conversion rates for the new and old page.\n",
    "\n",
    "pnew = new_page_converted.mean()\n",
    "pold = old_page_converted.mean()\n",
    "pnew - pold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 10000 simulations of the differences between the mean conversion rates for the new and old page\n",
    "\n",
    "p_diffs = []\n",
    "for _ in range(10000):\n",
    "    new_page_converted = np.random.choice([0,1], size=n_new, p = [1-p_new, p_new])\n",
    "    old_page_converted = np.random.choice([0,1], size=n_old, p = [1-p_old, p_old])\n",
    "    pnew = new_page_converted.mean()\n",
    "    pold = old_page_converted.mean()\n",
    "    p_diffs.append(pnew - pold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ploting a histogram for the distribution of the simulated differences\n",
    "\n",
    "p_diffs = np.array(p_diffs)\n",
    "plt.hist(p_diffs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0015782389853555567"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing the observed difference in conversion rates between the control and experiment groups in the a_data.csv\n",
    "\n",
    "control = df2.query('group == \"control\"')['converted'].mean()\n",
    "treatment = df2.query('group == \"treatment\"')['converted'].mean()\n",
    "obs_diff = treatment - control\n",
    "obs_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simulating the distribution from the null and finding the probability that the observed statistic came from this distribution.\n",
    "\n",
    "null_vals = np.random.normal(0, p_diffs.std(), p_diffs.size)\n",
    "plt.hist(null_vals)\n",
    "plt.axvline(x= obs_diff, color = 'r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9055"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the proportion of p_diffs greater than the observed actual difference\n",
    "\n",
    "p_val = (p_diffs > obs_diff).mean()\n",
    "p_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The value computed above is referred to as the P-value. The P-value against the type 1 error rate is used to measure the statistical significance and determine whether to fail to reject the null hypothesis or to reject the null hypothesis. In this case, the p-value of 0.91 against the type 1 error rate of 0.05 indicates that we fail to reject the null hypothesis. Therefore, in staying with the null hypothesis the new page does not effect any change on the conversion rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A built-in formula can also be used to achieve a similar result. Although using the built-in might be easier to code, the above portions are also walkthrough of the ideas critical to correctly thinking about statistical significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "# Calculating the number of conversions for each page\n",
    "\n",
    "convert_old = df2.query('landing_page == \"old_page\" & converted == \"1\"').shape[0]\n",
    "convert_new =  df2.query('landing_page == \"new_page\" & converted == \"1\"').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the total number of individuals who received each page\n",
    "\n",
    "n_old = df2.query('landing_page == \"old_page\"').shape[0]\n",
    "n_new = df2.query('landing_page == \"new_page\"').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17489, 17264)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_old, convert_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145274, 145310)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_old, n_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3109241984234394, 0.9050583127590245)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using stats.proportions_ztest to compute the test statistic(z-score) and p-value\n",
    "\n",
    "z_score, p_value = sm.stats.proportions_ztest([convert_old, convert_new], [n_old, n_new], alternative = 'smaller')\n",
    "z_score, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The `z-score` of 1.3 and `p-value` of 0.91 also corresponds to the findings using the simulated differences. When measured against an error rate of 0.05, the small `z-score` and high `p-value` indicates that we should fail to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regression'></a>\n",
    "### Part III - A regression approach\n",
    "\n",
    "> The result achieved in the A/B test in Part II above can also be achieved by performing regression. In this case, since each row has only two outcomes i.e. either a conversion or non-conversion in binary form, a Logistic Regression is the type of regression to be perfomed.\n",
    "\n",
    "> This involves using **statsmodels** to fit the regression model to see if there is a significant difference in conversion based on which page a customer receives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and intercept column in the df2 dataframe\n",
    "\n",
    "df2['intercept'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   intercept  ab_page  \n",
       "0          1        0  \n",
       "1          1        0  \n",
       "2          1        1  \n",
       "3          1        1  \n",
       "4          1        0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dummy variable for each page a user received by adding an ab_page column\n",
    "# which is 1 when an individual receives the treatment and 0 if control\n",
    "\n",
    "df2['ab_page'] = pd.get_dummies(df2['group'])['treatment']\n",
    "\n",
    "# Confirming the intercept and ab_page column is a part of the df2 dataframe\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366118\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "# Using statsmodel to Instantiate and fit the model to predict whether or not an individual converts based on the type of page received\n",
    "\n",
    "log_model = sm.Logit(df2['converted'], df2[['intercept', 'ab_page']])\n",
    "result = log_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>converted</td>          <td>AIC:</td>        <td>212780.3502</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2020-08-17 19:50</td>       <td>BIC:</td>        <td>212801.5095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>290584</td>       <td>Log-Likelihood:</td>  <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>1</td>            <td>LL-Null:</td>      <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>290582</td>        <td>LLR p-value:</td>      <td>0.18988</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>      <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-1.9888</td>  <td>0.0081</td>  <td>-246.6690</td> <td>0.0000</td> <td>-2.0046</td> <td>-1.9730</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>-0.0150</td>  <td>0.0114</td>   <td>-1.3109</td>  <td>0.1899</td> <td>-0.0374</td> <td>0.0074</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.000      \n",
       "Dependent Variable: converted        AIC:              212780.3502\n",
       "Date:               2020-08-17 19:50 BIC:              212801.5095\n",
       "No. Observations:   290584           Log-Likelihood:   -1.0639e+05\n",
       "Df Model:           1                LL-Null:          -1.0639e+05\n",
       "Df Residuals:       290582           LLR p-value:      0.18988    \n",
       "Converged:          1.0000           Scale:            1.0000     \n",
       "No. Iterations:     6.0000                                        \n",
       "-------------------------------------------------------------------\n",
       "              Coef.   Std.Err.      z      P>|z|    [0.025   0.975]\n",
       "-------------------------------------------------------------------\n",
       "intercept    -1.9888    0.0081  -246.6690  0.0000  -2.0046  -1.9730\n",
       "ab_page      -0.0150    0.0114    -1.3109  0.1899  -0.0374   0.0074\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary of the model created\n",
    "result.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The p-value associated with `ab_page` from the logistic regression is given as 0.1899. This p-value differs totally from that obtained using A/B testing and the inbuilt `stats.proportions_z` test function. This is because the hypothesis test for the logistic regression is a two-tailed test while that for the A/B testing is a one-tailed test.\n",
    "\n",
    "> Although the p-value between the simulated and observed difference and the p-value obtained from the logistic regression are different in values, they both do not show any statistical significance. They two p-values support the decision to fail to reject the null and show that the new page does not improve the conversion rate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Adding other factors into a regression model help to improve the prediction of the response variable, although this may change the statistical significance of previous variables present in the model and the model may give unpredictable results. This is most likely due to multicollinearity between the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Along with testing if the conversion rate changes for different pages, an effect based on which country a user lives in will be added by reading in the **countries.csv** dataset and merging it together with the `df2` dataset on the appropriate rows. \n",
    "> On the merged dataset, a regression model is created to measure if the country has an impact on the conversion rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>834778</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>928468</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>822059</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>711597</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>710616</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id country\n",
       "0   834778      UK\n",
       "1   928468      US\n",
       "2   822059      UK\n",
       "3   711597      UK\n",
       "4   710616      UK"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the countries dataset into a dataframe\n",
    "\n",
    "dff = pd.read_csv('countries.csv')\n",
    "dff.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['UK', 'US', 'CA'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for the number of unique values in the country column\n",
    "\n",
    "dff.country.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   intercept  ab_page country  \n",
       "0          1        0      US  \n",
       "1          1        0      US  \n",
       "2          1        1      US  \n",
       "3          1        1      US  \n",
       "4          1        0      US  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a new dataframe by merging the countries dataset with the df2 dataset Using the merge() function\n",
    "\n",
    "df_all = pd.merge(df2, dff, on='user_id', how=\"inner\")\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>country</th>\n",
       "      <th>UK</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   intercept  ab_page country  UK  US  \n",
       "0          1        0      US   0   0  \n",
       "1          1        0      US   0   0  \n",
       "2          1        1      US   0   0  \n",
       "3          1        1      US   0   0  \n",
       "4          1        0      US   0   0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dummy variables for the country dataset\n",
    "df_all[['UK', 'US', 'CA']] = pd.get_dummies(df_all['country'])\n",
    "\n",
    "# Using the CA dummy variable as a baseline therefore it is dropped\n",
    "df_all.drop('CA', axis=1, inplace=True)\n",
    "\n",
    "# Checking to confirm that the baseline has been dropped\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366116\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>converted</td>          <td>AIC:</td>        <td>212780.8333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2020-08-17 19:50</td>       <td>BIC:</td>        <td>212812.5723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>290584</td>       <td>Log-Likelihood:</td>  <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>2</td>            <td>LL-Null:</td>      <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>290581</td>        <td>LLR p-value:</td>      <td>0.19835</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>      <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-1.9967</td>  <td>0.0068</td>  <td>-292.3145</td> <td>0.0000</td> <td>-2.0101</td> <td>-1.9833</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>-0.0408</td>  <td>0.0269</td>   <td>-1.5178</td>  <td>0.1291</td> <td>-0.0935</td> <td>0.0119</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>US</th>        <td>0.0099</td>   <td>0.0133</td>   <td>0.7458</td>   <td>0.4558</td> <td>-0.0161</td> <td>0.0360</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.000      \n",
       "Dependent Variable: converted        AIC:              212780.8333\n",
       "Date:               2020-08-17 19:50 BIC:              212812.5723\n",
       "No. Observations:   290584           Log-Likelihood:   -1.0639e+05\n",
       "Df Model:           2                LL-Null:          -1.0639e+05\n",
       "Df Residuals:       290581           LLR p-value:      0.19835    \n",
       "Converged:          1.0000           Scale:            1.0000     \n",
       "No. Iterations:     6.0000                                        \n",
       "-------------------------------------------------------------------\n",
       "              Coef.   Std.Err.      z      P>|z|    [0.025   0.975]\n",
       "-------------------------------------------------------------------\n",
       "intercept    -1.9967    0.0068  -292.3145  0.0000  -2.0101  -1.9833\n",
       "UK           -0.0408    0.0269    -1.5178  0.1291  -0.0935   0.0119\n",
       "US            0.0099    0.0133     0.7458  0.4558  -0.0161   0.0360\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating and fitting a model to check for the impact of country on conversion rate\n",
    "log_mod = sm.Logit(df_all['converted'], df_all[['intercept', 'UK', 'US']])\n",
    "result1 = log_mod.fit()\n",
    "\n",
    "# Checking for the summary of the model fitted\n",
    "result1.summary2()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> From the summary above of the fitted model obtained to measure the impact of country on the conversion rate, the p-values of both `UK`  and `US` are higher than the error rate of 0.05. It therefore appears that the country a user lives in therefore has no impact on the conversion rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> After observing the individual factors of country and page on the conversion rate, an interaction between page and country will be observed to see if there are any significant effects on the conversion rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a columns containing the interaction between page and country\n",
    "df_all['UK_page'] = df_all['UK'] * df_all['ab_page']\n",
    "df_all['US_page'] = df_all['US'] * df_all['ab_page']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366109\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>converted</td>          <td>AIC:</td>        <td>212782.6602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2020-08-17 19:50</td>       <td>BIC:</td>        <td>212846.1381</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>290584</td>       <td>Log-Likelihood:</td>  <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>5</td>            <td>LL-Null:</td>      <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>290578</td>        <td>LLR p-value:</td>      <td>0.19199</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>      <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-1.9865</td>  <td>0.0096</td>  <td>-206.3440</td> <td>0.0000</td> <td>-2.0053</td> <td>-1.9676</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>-0.0206</td>  <td>0.0137</td>   <td>-1.5052</td>  <td>0.1323</td> <td>-0.0473</td> <td>0.0062</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>-0.0175</td>  <td>0.0377</td>   <td>-0.4652</td>  <td>0.6418</td> <td>-0.0914</td> <td>0.0563</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>US</th>        <td>-0.0057</td>  <td>0.0188</td>   <td>-0.3057</td>  <td>0.7598</td> <td>-0.0426</td> <td>0.0311</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK_page</th>   <td>-0.0469</td>  <td>0.0538</td>   <td>-0.8718</td>  <td>0.3833</td> <td>-0.1523</td> <td>0.0585</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>US_page</th>   <td>0.0314</td>   <td>0.0266</td>   <td>1.1807</td>   <td>0.2377</td> <td>-0.0207</td> <td>0.0835</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.000      \n",
       "Dependent Variable: converted        AIC:              212782.6602\n",
       "Date:               2020-08-17 19:50 BIC:              212846.1381\n",
       "No. Observations:   290584           Log-Likelihood:   -1.0639e+05\n",
       "Df Model:           5                LL-Null:          -1.0639e+05\n",
       "Df Residuals:       290578           LLR p-value:      0.19199    \n",
       "Converged:          1.0000           Scale:            1.0000     \n",
       "No. Iterations:     6.0000                                        \n",
       "-------------------------------------------------------------------\n",
       "              Coef.   Std.Err.      z      P>|z|    [0.025   0.975]\n",
       "-------------------------------------------------------------------\n",
       "intercept    -1.9865    0.0096  -206.3440  0.0000  -2.0053  -1.9676\n",
       "ab_page      -0.0206    0.0137    -1.5052  0.1323  -0.0473   0.0062\n",
       "UK           -0.0175    0.0377    -0.4652  0.6418  -0.0914   0.0563\n",
       "US           -0.0057    0.0188    -0.3057  0.7598  -0.0426   0.0311\n",
       "UK_page      -0.0469    0.0538    -0.8718  0.3833  -0.1523   0.0585\n",
       "US_page       0.0314    0.0266     1.1807  0.2377  -0.0207   0.0835\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating and fitting a model to check for the impact of both ab_page and country on the conversion rate\n",
    "logistic_mod = sm.Logit(df_all['converted'], df_all[['intercept', 'ab_page', 'UK', 'US', 'UK_page', 'US_page']])\n",
    "results = logistic_mod.fit()\n",
    "\n",
    "# Checking for the summary of the model fitted\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusions'></a>\n",
    "## Conclusion\n",
    "\n",
    "> A logistic regression can be used as an alternative way to confirm the results of AB testing. In this project creating a logistic model to predict the impact of the page a user received, the country a user lives in and the interaction between the page an d country gives a summary with p-values greater than 0.05. These p-values are not statistically significant and therefore indicate that the variables page and country or the interaction between these variables do not have any significant effect on the conversion rate.\n",
    "\n",
    "> In conclusion, the new page does not improve the conversion rate and we therefore fail to reject the null hypothesis. The company is therefore advised to continue using the old page as there's no statistical significance to show that the new page will improve the conversion rate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
